{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../data/train.csv', parse_dates=['date'])\n",
    "keys = pd.read_csv('../data/key.csv')\n",
    "weather = pd.read_csv('../data/weather.csv', parse_dates=['date'])\n",
    "df_1 = pd.merge(weather, keys)\n",
    "df_1 = pd.merge(df_1, sales)\n",
    "\n",
    "dates = df_1['date'].dt\n",
    "df_1['year'] = dates.year\n",
    "df_1['month'] = dates.month\n",
    "df_1['day'] = dates.day\n",
    "\n",
    "final_sample = pd.read_csv('../data/01. final_sample')\n",
    "trimmed = final_sample.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_nbr_tendency_finely(store_nbr, year, month_start=-1, month_end=-1, graph=True):\n",
    "    '''\n",
    "    input\n",
    "        1. store_nbr = 스토어 번호\n",
    "        2. year = 연도\n",
    "        3. month_start = 시작달\n",
    "        4. month_start = 끝달\n",
    "        5. graph = 위의 정보에 대한 item_nbr 그래프 출력여부\n",
    "    \n",
    "    output\n",
    "        1. store_nbr, year, month로 filtering한 item_nbr의 pivot 테이블\n",
    "    '''\n",
    "    store = df_1[(df_1['store_nbr'] == store_nbr) &\n",
    "                 (df_1['year'] == year)]\n",
    "\n",
    "    if month_start != -1:\n",
    "        if month_end == -1:\n",
    "            month_end = month_start + 1\n",
    "        store = store[(month_start <= store['month']) & (store['month'] < month_end)]\n",
    "\n",
    "    pivot = store.pivot_table(index='item_nbr',\n",
    "                              columns='date',\n",
    "                              values='units',\n",
    "                              aggfunc=np.sum)\n",
    "\n",
    "    zero_index = pivot == 0\n",
    "    pivot = pivot[pivot != 0].dropna(axis=0, how='all')\n",
    "    pivot[zero_index] = 0\n",
    "\n",
    "    if graph:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot, cmap=\"YlGnBu\", annot=True, fmt='.0f')\n",
    "        plt.show()\n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_tendency(store_nbr, year, month_start = -1, month_end = -1):\n",
    "    '''\n",
    "    input:\n",
    "        위와 같음\n",
    "        \n",
    "    output:\n",
    "        위의 정보로 filtering한 train,key,weather DataFrame\n",
    "    '''\n",
    "    store = df_1[(df_1['store_nbr'] == store_nbr) &\n",
    "                 (df_1['year'] == year)]\n",
    "    \n",
    "    if month_start!=-1:\n",
    "        if month_end == -1:\n",
    "            month_end = month_start + 1\n",
    "        store = store[(month_start <= store['month']) & (store['month'] < month_end)]\n",
    "    \n",
    "    store = store.drop(labels=['item_nbr','units'],axis=1)\n",
    "#     store = store.iloc[:,:]\n",
    "    \n",
    "    store = store.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    \n",
    "    store.index.name='date'\n",
    "    store.index = store['date']\n",
    "        \n",
    "    return store\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(store_nbr, year, month_start=-1, month_end = -1):\n",
    "    '''\n",
    "    input:\n",
    "        위와 같음\n",
    "    output:\n",
    "        missing, tracing data를 제외한\n",
    "        팔린 item_nbr별 각 weather feature에 대한 pearsonr, pvalue를 담은 dictionary\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Use-case\n",
    "        1. 7번 store, 2012년 1월부터 12월까지 item_nbr별 상관관계를 알고 싶다\n",
    "        get_correlation(7,2012)\n",
    "        \n",
    "        2. 7번 store, 2012년 1월부터 3월까지 item_nbr별 상관관계를 알고 싶다\n",
    "        get_correlation(7,2012,1,3)\n",
    "        \n",
    "        3. 7번 store, 2012년 5월만 item_nbr별 상관관계를 알고 싶다\n",
    "        get_correlation(7,2012,5)\n",
    "    '''\n",
    "    correlation = dict()\n",
    "\n",
    "    units_table = item_nbr_tendency_finely(store_nbr, year, month_start, month_end, graph=False)\n",
    "    weather_table = weather_tendency(store_nbr, year, month_start, month_end)\n",
    "\n",
    "    weather = list(weather_table.columns[3:20])\n",
    "    weather.remove('codesum')\n",
    "\n",
    "    item_nbr = units_table.index\n",
    "\n",
    "    inner = dict()\n",
    "\n",
    "    for feature in weather:\n",
    "        for units in item_nbr:\n",
    "\n",
    "            a = weather_table[feature].copy()\n",
    "            b = units_table.loc[units].copy()\n",
    "\n",
    "            a = a.apply(lambda x: x.replace(' ', ''))\n",
    "            a = a.apply(lambda x: x.replace('-', ''))\n",
    "\n",
    "            missing_index = (a.str.contains('M')) | (a.str.contains('T')) | (\n",
    "                a.str.contains('-')) | (a.str.contains(' '))\n",
    "\n",
    "            a[missing_index] = np.nan\n",
    "            b[missing_index] = np.nan\n",
    "\n",
    "            a.dropna(axis=0, inplace=True)\n",
    "            b.dropna(axis=0, inplace=True)\n",
    "\n",
    "            inner[(units, feature)] = sp.stats.pearsonr(a.astype(float), b)\n",
    "\n",
    "            correlation[(store_nbr, year, month_start, month_end)] = inner\n",
    "\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_me_pearson(pearson_dict):\n",
    "    '''\n",
    "    input:\n",
    "        get_correlation의 return (상관관계 dictionary)\n",
    "    output:\n",
    "        dictionary를 직관적으로 출력함\n",
    "    '''\n",
    "    for key,val in get_correlation(7,2012).items():\n",
    "        print(key)\n",
    "        for each,each_val in val.items():\n",
    "            print('\\t',each,each_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ej/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:2998: RuntimeWarning: Mean of empty slice.\n",
      "  mx = x.mean()\n",
      "/home/ej/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ej/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:2999: RuntimeWarning: Mean of empty slice.\n",
      "  my = y.mean()\n",
      "/home/ej/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "store_nbrs = range(7,8)\n",
    "years=range(2012,2013)\n",
    "months = range(1,13)\n",
    "\n",
    "total_pearsonr = dict()\n",
    "\n",
    "for store_nbr in store_nbrs:\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "#             print(year,month)\n",
    "            pearsonr = get_correlation(store_nbr,year,month)\n",
    "            total_pearsonr.update(pearsonr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ej/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2012, -1, -1)\n",
      "\t (7, 'preciptotal') (0.02539069927921189, 0.6534885999099429)\n",
      "\t (23, 'sealevel') (0.1413760647135836, 0.006823818989687476)\n",
      "\t (93, 'depart') (0.0430869122415797, 0.414390764060815)\n",
      "\t (5, 'resultspeed') (-0.000546278544212438, 0.9917014804935169)\n",
      "\t (93, 'preciptotal') (0.16026508052023067, 0.004350397248605468)\n",
      "\t (93, 'stnpressure') (-0.025121142894480225, 0.6328582142377869)\n",
      "\t (5, 'sunset') (-0.013822858594614783, 0.7924025289760432)\n",
      "\t (23, 'avgspeed') (-0.03132938266372468, 0.5512975389569583)\n",
      "\t (5, 'resultdir') (-0.02066557484459113, 0.6939479807728344)\n",
      "\t (23, 'wetbulb') (-0.05998953892844458, 0.2536123129617649)\n",
      "\t (5, 'wetbulb') (-0.09331104635663716, 0.0754007127544108)\n",
      "\t (5, 'heat') (0.19739142794896797, 0.00016024297777646098)\n",
      "\t (93, 'snowfall') (nan, 1.0)\n",
      "\t (5, 'depart') (0.04308434650976235, 0.4144185838318908)\n",
      "\t (5, 'avgspeed') (0.007701007672754401, 0.8835877232206184)\n",
      "\t (93, 'sunset') (0.01636389533539364, 0.7553595091751396)\n",
      "\t (7, 'stnpressure') (-0.08817251002286182, 0.09301353397389713)\n",
      "\t (7, 'snowfall') (nan, 1.0)\n",
      "\t (23, 'depart') (0.07603807974844869, 0.14935849890868383)\n",
      "\t (5, 'cool') (-0.032396904395508144, 0.539501175752865)\n",
      "\t (93, 'wetbulb') (0.11054771828463178, 0.03500265466563533)\n",
      "\t (7, 'sunset') (0.19450438807898007, 0.00018473523001148463)\n",
      "\t (7, 'sunrise') (-0.058937273553174796, 0.2613910708955609)\n",
      "\t (93, 'sunrise') (-0.03370537422663758, 0.5209290717176127)\n",
      "\t (7, 'avgspeed') (0.029743796062091016, 0.5716325513566491)\n",
      "\t (23, 'sunset') (-0.12267810100104554, 0.019048263443024106)\n",
      "\t (5, 'sealevel') (0.11301900344383121, 0.030870363476181134)\n",
      "\t (7, 'wetbulb') (0.01212885703365156, 0.8176128157915777)\n",
      "\t (23, 'dewpoint') (-0.0717738708917582, 0.17121828629513086)\n",
      "\t (7, 'tavg') (0.0035765695740195644, 0.9460090360205681)\n",
      "\t (93, 'resultspeed') (-0.011329959121093379, 0.8292036544842697)\n",
      "\t (5, 'tavg') (-0.12137801589834839, 0.02107049389731149)\n",
      "\t (23, 'tmin') (-0.024866829855208324, 0.6363057821836989)\n",
      "\t (7, 'cool') (0.008200549997614435, 0.8766063451436716)\n",
      "\t (5, 'snowfall') (nan, 1.0)\n",
      "\t (5, 'preciptotal') (0.005492044163217863, 0.9226570376007677)\n",
      "\t (93, 'avgspeed') (0.04060114618265921, 0.43995175933072095)\n",
      "\t (23, 'tavg') (-0.045655442190484015, 0.38709585303678296)\n",
      "\t (7, 'dewpoint') (0.01992476734238231, 0.7043952191964113)\n",
      "\t (23, 'heat') (0.06414557538066203, 0.22406434868746228)\n",
      "\t (93, 'sealevel') (-0.03105574988272162, 0.55423447602002)\n",
      "\t (93, 'resultdir') (0.06613527322454688, 0.2074677247864595)\n",
      "\t (7, 'tmin') (0.004401142043765636, 0.9333108321020509)\n",
      "\t (93, 'tavg') (0.05223834371554498, 0.3222903501763481)\n",
      "\t (93, 'dewpoint') (0.1459619825857725, 0.005205835345499121)\n",
      "\t (5, 'tmin') (-0.07751359130214516, 0.13994389337994312)\n",
      "\t (93, 'cool') (0.0013307002769218056, 0.979898922203858)\n",
      "\t (7, 'resultdir') (-0.008030386848263613, 0.8784798575934963)\n",
      "\t (7, 'heat') (0.002783779208173577, 0.9579641893858764)\n",
      "\t (7, 'sealevel') (-0.0815971218225983, 0.11967015477051325)\n",
      "\t (23, 'resultspeed') (-0.025039749416206354, 0.6334919955497078)\n",
      "\t (23, 'preciptotal') (-0.008991095636879278, 0.873712259788751)\n",
      "\t (23, 'stnpressure') (0.1512641648740222, 0.003819793950808066)\n",
      "\t (23, 'snowfall') (nan, 1.0)\n",
      "\t (93, 'tmin') (0.1068799116642834, 0.04155332720724622)\n",
      "\t (23, 'resultdir') (-0.04547558709432674, 0.3863377057933668)\n",
      "\t (5, 'sunrise') (0.1079989467534099, 0.03918155102035344)\n",
      "\t (7, 'depart') (-0.05615816241348862, 0.28726322409877886)\n",
      "\t (23, 'sunrise') (0.040526304642463984, 0.4401645420746235)\n",
      "\t (5, 'dewpoint') (-0.07568296514313719, 0.14901153042300766)\n",
      "\t (5, 'stnpressure') (0.1100190187502882, 0.03588900909169614)\n",
      "\t (7, 'resultspeed') (0.0020950956438734653, 0.9681812258934072)\n",
      "\t (23, 'cool') (-0.020696899217078252, 0.6951178733454078)\n",
      "\t (93, 'heat') (-0.09992218986316215, 0.05786931553462509)\n"
     ]
    }
   ],
   "source": [
    "show_me_pearson(get_correlation(7,2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(store_nbr, year, month = -1):\n",
    "    correlation = dict()\n",
    "\n",
    "    units_table = item_nbr_tendency_finely(store_nbr, year, month, graph=False)\n",
    "    weather_table = weather_tendency(store_nbr, year, month)\n",
    "\n",
    "    weather = ['cool']\n",
    "\n",
    "    item_nbr = units_table.index\n",
    "\n",
    "    inner=dict()\n",
    "    \n",
    "    for feature in weather:\n",
    "        for units in item_nbr:\n",
    "            \n",
    "            print(feature, units)\n",
    "            \n",
    "            a = weather_table[feature].copy()\n",
    "            b = units_table.loc[units].copy()\n",
    "\n",
    "            return a\n",
    "            \n",
    "            missing_index = (a.str.contains('M')) | (a.str.contains('T')) | (a.str.contains('-')) | (a.str.contains(' '))\n",
    "\n",
    "            a[missing_index] = np.nan\n",
    "            b[missing_index] = np.nan\n",
    "\n",
    "            a.dropna(axis=0, inplace=True)\n",
    "            b.dropna(axis=0, inplace=True)\n",
    "\n",
    "            print('\\t',a,b)\n",
    "            \n",
    "            \n",
    "            inner[(units, feature)] = sp.stats.pearsonr(a.astype(float), b)\n",
    "        \n",
    "            correlation[(store_nbr, year,month)] = inner\n",
    "\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_tendency(7,2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
